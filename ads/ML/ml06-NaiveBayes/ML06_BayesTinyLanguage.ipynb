{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "This python script will do as follow \n",
    "\n",
    "1. Genereate dataset of 100 sentenses \n",
    "2. Pick the words of prefrence in the dataset \n",
    "\n",
    "The Machine learning part \n",
    "* show and proof the more distinct prefrencese are the more accurate your classifier is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code to generate Sentenses with verb_list\n",
    "import random\n",
    "import csv\n",
    "\n",
    "# Can\n",
    "verb_list =  [\"run\",\"just\",\"do\",\"it\",\"let's\",\"make\",\"America\",\"Great\",\"Again\",\"I\",\"Doooiii\"]\n",
    "def randome_gen(list_of_words):\n",
    "    number_of_words = len(verb_list) # Get the length of the word list\n",
    "    random_word_number = random.randint(0,number_of_words -1) # pick a random number up to the end of the list\n",
    "    selected_word = list_of_words[random_word_number] # select the word at the number spot\n",
    "    return selected_word\n",
    "\n",
    "# The <Adjective> <Noun> <verb> the <adjective> <noun>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  do Great Doooiii run run I America America do I\n"
     ]
    }
   ],
   "source": [
    "# Test The Method \n",
    "list_of_words = ' '\n",
    "for x in range(0,10):\n",
    "    list_of_words += \" \" + randome_gen(verb_list)\n",
    "print(list_of_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning part 1) Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author Mr.Green\n",
    "verb_list_G = [\"I\",\"run\",\"let's\",\"Do\",\"it\",\"Good\",\"Morning\",\"saw\",\"cow\",\"mac\",\"python\",\"google\"\n",
    "             ,\"like\",\"love\",\"am\",\"one\",\"page\",\"knock\",\"show\",\"jump\",\"we\"]\n",
    "#Author Mr.Blue\n",
    "verb_list_B = [\"I\",\"love\",\"python\",\"google\",\"car\",\"speed\",\"just\",\"do\",\"it\",\n",
    "               \"meet\",\"package\",\"sound\",\"smile\",\"eat\",\"done\",\"sleep\",\"walk\",\"talk\",\"hack\",\"crack\",\"track\",\"stack\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences_G = ' '\n",
    "sentences_B = ' '\n",
    "for x in range(0,1000):\n",
    "    sentences_G += ' ' + randome_gen(verb_list_G)\n",
    "    sentences_B += ' ' + randome_gen(verb_list_B)\n",
    "\n",
    "span = 10\n",
    "words_G = sentences_G.split(' ')\n",
    "words_B = sentences_B.split(' ')\n",
    "\n",
    "words_list_G = [' '.join(words_G[i:i+span]) for i in range(0, len(words_G), span)]\n",
    "words_list_B = [' '.join(words_B[i:i+span]) for i in range(0, len(words_B), span)]\n",
    "\n",
    "filepath = '/home/rwx/Documents/Fontys-assignment/ads/ML/ml06-NaiveBayes/my_corpus.csv' \n",
    "def write_to_csv(mylist):\n",
    "    try:\n",
    "        writer = csv.writer(open(filepath,'a',))\n",
    "        writer.writerows(mylist)\n",
    "    except:\n",
    "        print('something happened')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write to file \n",
    "write_to_csv(words_list_G)\n",
    "write_to_csv(words_list_B)\n",
    "# Spliting and combining \n",
    "words_list = words_list_B + words_list_G\n",
    "\n",
    "# Authors of each line\n",
    "authors = []\n",
    "for x in range(0,101):\n",
    "    authors.append('mr.Green')\n",
    "for x in range(0,101):\n",
    "    authors.append('mr.Blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This step we define the cross validation \n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from numpy import mean\n",
    "from scipy.stats import sem\n",
    "\n",
    "def evaluate_cross_validation(clf, X, y, K):\n",
    "    # Create a k-fold cross validation iterator of k=5 folds\n",
    "    cv = KFold(len(y), K, shuffle=True, random_state=0)\n",
    "    # By default the score used is the one returned by score method of the estimator (accuracy)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv)\n",
    "    print(scores)\n",
    "    print(\"Mean score: {0:.3f}\".format(mean(scores)))\n",
    "    print(\"Standard error of the mean: (+/-{0:.3f})\".format(sem(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mr:Green\n",
      "[[1 0 2 0 0 0 1 0 1 0 0 0 0 2 0 0 0]\n",
      " [2 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0]]\n",
      "\n",
      "['car', 'cow', 'do', 'good', 'google', 'it', 'just', 'let', 'love', 'mac', 'meet', 'morning', 'package', 'python', 'run', 'saw', 'speed']\n"
     ]
    }
   ],
   "source": [
    "# Note that we create our validation folds from our complete dataset as contrasted to creating folds\n",
    "# from the training set in the SVM notebook\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "\n",
    "print()\n",
    "print('Mr:Green')\n",
    "print(vec.fit_transform(words_list).toarray()[:2])\n",
    "print()\n",
    "print(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.]\n",
      "Mean score: 1.000\n",
      "Standard error of the mean: (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Naive Bayes classifier (see below) can only deal with numeric data.\n",
    "So we have to map the texts to numeric data. That's in short what the vectorizer does: \n",
    "it creates a vector of features that we can give numeric values. The CountVectorizer is one of the simplest\n",
    "vectorizers available: it just creates a feature for each unique word in the text an then counts occurrences of\n",
    "each word in a text.\n",
    "\n",
    "There are also other vectorizers available in sklearn, such as the HashingVectorizer.\n",
    "Using the HashingVectorizer leads to a smaller feature space as different unique words may be hashed to the same bucket.\n",
    "The buckets form the feature space. Also, vectorizers may have paramaters. See the sklearn docs for which params you can use.\n",
    "'''\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "clf = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])\n",
    "\n",
    "\n",
    "evaluate_cross_validation(clf, words_list,authors, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it Do Do saw run cow cow Do Morning python', 'mac Good I run python I mac Good Do Do']\n",
      "['mr.Blue', 'mr.Blue']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(words_list, authors, test_size=0.25, random_state=33)\n",
    "print(X_train[:2])\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Accuracy on training set:\")\n",
    "    print(clf.score(X_train, y_train))\n",
    "    print(\"Accuracy on testing set:\")\n",
    "    print(clf.score(X_test, y_test))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "1.0\n",
      "Accuracy on testing set:\n",
      "1.0\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    mr.Blue       1.00      1.00      1.00        26\n",
      "   mr.Green       1.00      1.00      1.00        25\n",
      "\n",
      "avg / total       1.00      1.00      1.00        51\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26  0]\n",
      " [ 0 25]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mr.Blue'], \n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([\"python mac just do it amaerica hey\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
